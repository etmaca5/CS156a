{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onoBHBAWHU3_"
      },
      "source": [
        "# Hoeffding Inequality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VOq56xvtHoAW"
      },
      "outputs": [],
      "source": [
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "7a_JlpSfHB4M",
        "outputId": "ac28ab32-994a-4cc2-8fbb-18d817050c1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "v_one : 0.5002999999999991\n",
            "v_rand : 0.5010170000000012\n",
            "v_min : 0.037241999999977085\n"
          ]
        }
      ],
      "source": [
        "# array represent the frequency of heads for each coin\n",
        "\n",
        "sims = 100000\n",
        "v_one_average = 0\n",
        "v_rand = 0\n",
        "v_min = 0\n",
        "for n in range(sims):\n",
        "  coins = [0] * 1000\n",
        "  for j in range(len(coins)):\n",
        "    total = 0\n",
        "    for i in range(10):\n",
        "      total += random.randint(0,1) / 10\n",
        "      coins[j] = total\n",
        "  v_one_average += coins[0]\n",
        "  v_rand += coins[random.randint(0, 999)]\n",
        "  v_min += min(coins)\n",
        "\n",
        "\n",
        "print(\"v_one : \" + str(v_one_average / sims))\n",
        "print(\"v_rand : \" + str(v_rand / sims))\n",
        "print(\"v_min : \" + str(v_min / sims))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sj13EvpVcnGw"
      },
      "source": [
        "# Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "g6dxJPShkWuk"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "tpilHUFrcm7G"
      },
      "outputs": [],
      "source": [
        "# global vars\n",
        "min = -1\n",
        "max = 1\n",
        "d = 2\n",
        "\n",
        "def create_X(N):\n",
        "  X = [(0, 0, 0) for i in range(N)]\n",
        "  for i in range(N):\n",
        "    X[i] = (random.uniform(min, max), random.uniform(min, max), 1) #(x, y, artifical bias)\n",
        "  return np.array(X)\n",
        "\n",
        "def get_target_function():\n",
        "  x1 = random.uniform(min, max)\n",
        "  y1 = random.uniform(min, max)\n",
        "  x2 = random.uniform(min, max)\n",
        "  y2 = random.uniform(min, max)\n",
        "  m =  (y1 - y2) / (x1 - x2)\n",
        "  b = y1 - (m * x1)\n",
        "  return (m, b)\n",
        "\n",
        "def create_y(X, target_func):\n",
        "  y = []\n",
        "  for i in range(X.shape[0]):\n",
        "    point = X[i]\n",
        "    point_class = -1\n",
        "    if point[0] * target_func[0] + target_func[1] > point[1]:\n",
        "      point_class = 1\n",
        "    y.append(point_class)\n",
        "  return np.array(y)\n",
        "\n",
        "def find_weight_vec(X, y):\n",
        "  pseudo_inv = np.dot(np.linalg.inv(np.dot(X.T, X)), X.T)\n",
        "  w = np.array(np.dot(pseudo_inv, y))\n",
        "  return w\n",
        "\n",
        "def predict(w, point):\n",
        "  guess = np.dot(w, point)\n",
        "  if guess > 0: return 1\n",
        "  else: return -1\n",
        "\n",
        "\n",
        "def linear_regression(N):\n",
        "  X = create_X(N)\n",
        "  target_function = get_target_function()\n",
        "  y = create_y(X, target_function)\n",
        "  w = find_weight_vec(X, y)\n",
        "  return w, target_function, X, y\n",
        "\n",
        "def in_sample_points_eval(N):\n",
        "  incorrect = 0\n",
        "  w, target, X, y = linear_regression(N)\n",
        "  for i in range(X.shape[0]):\n",
        "    point = X[i]\n",
        "    if predict(w, point) != y[i]:\n",
        "      incorrect += 1\n",
        "  return incorrect / N\n",
        "\n",
        "def out_of_sample_points_eval(N):\n",
        "  incorrect = 0\n",
        "  w, target, X, y = linear_regression(N)\n",
        "  num_points = 1000\n",
        "  new_points = create_X(num_points)\n",
        "  new_point_classification = create_y(new_points, target)\n",
        "  for i in range(new_points.shape[0]):\n",
        "    point = new_points[i]\n",
        "    if predict(w, point) != new_point_classification[i]:\n",
        "      incorrect += 1\n",
        "  return incorrect / num_points\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "SG1RepCjr5K8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The average fraction of incorrectly classified points is: 0.04035000000000011 for in sample\n"
          ]
        }
      ],
      "source": [
        "sims = 1000\n",
        "total = 0\n",
        "for i in range(sims):\n",
        "  total += in_sample_points_eval(100)\n",
        "print(\"The average fraction of incorrectly classified points is: \" + str(total / sims) + \" for in sample\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "nE-Z9MHd3EVp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The average fraction of incorrectly classified points is: 0.047124000000000006 for out of sample\n"
          ]
        }
      ],
      "source": [
        "sims = 1000\n",
        "total = 0\n",
        "for i in range(sims):\n",
        "  total += out_of_sample_points_eval(100)\n",
        "print(\"The average fraction of incorrectly classified points is: \" + str(total / sims) + \" for out of sample\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "zbm60_3j39yC"
      },
      "outputs": [],
      "source": [
        "def create_points(N):\n",
        "  X = [(0, 0, 0) for i in range(N)]\n",
        "  for i in range(N):\n",
        "    X[i] = (random.uniform(min, max), random.uniform(min, max), 1) #(x, y, artifical bias)\n",
        "  return np.array(X)\n",
        "\n",
        "def get_target_function():\n",
        "  x1 = random.uniform(min, max)\n",
        "  y1 = random.uniform(min, max)\n",
        "  x2 = random.uniform(min, max)\n",
        "  y2 = random.uniform(min, max)\n",
        "  m =  (y1 - y2) / (x1 - x2)\n",
        "  b = y1 - (m * x1)\n",
        "  return (m, b)\n",
        "\n",
        "def create_y(X, target_func):\n",
        "  y = []\n",
        "  for i in range(X.shape[0]):\n",
        "    point = X[i]\n",
        "    point_class = -1\n",
        "    if point[0] * target_func[0] + target_func[1] > point[1]:\n",
        "      point_class = 1\n",
        "    y.append(point_class)\n",
        "  return np.array(y)\n",
        "\n",
        "def update_weights(w, point, point_class):\n",
        "  w[0] += point[0] * point_class\n",
        "  w[1] += point[1] * point_class\n",
        "  w[2] += point[2] * point_class\n",
        "\n",
        "def guess_class(w, point):\n",
        "  predict =  np.dot(w, point)\n",
        "  if predict > 0: return 1\n",
        "  else: return -1\n",
        "\n",
        "def PLA(N, target_func, w):\n",
        "  count = 0\n",
        "  X = create_points(N)\n",
        "  y = create_y(X, target_func)\n",
        "  i = 0\n",
        "  while i < X.shape[0]:\n",
        "    point = X[i]\n",
        "    point_class = y[i]\n",
        "    guess = guess_class(w, point)\n",
        "    if guess != point_class:\n",
        "      update_weights(w, point, point_class)\n",
        "      i = 0\n",
        "      count += 1\n",
        "    else:\n",
        "      i += 1\n",
        "  return w, count\n",
        "\n",
        "def convergence_time(N):\n",
        "  sims = 1000\n",
        "  total = 0\n",
        "  for i in range(sims):\n",
        "    w, target, X, y = linear_regression(N)\n",
        "    _, step_count = PLA(N, target, w)\n",
        "    total += step_count\n",
        "  print(\"The average convergence is \" + str(total / sims) + \" for N = \" + str(N))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "CXVEQTrB4i3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The average convergence is 8.627 for N = 10\n"
          ]
        }
      ],
      "source": [
        "convergence_time(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dt-oDsBnKpVs"
      },
      "source": [
        "#Non-Linear Transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "5iV2mZrGKw3f"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "rest of functions used in linear regression defined earlier\n",
        "\"\"\"\n",
        "def create_noisy_y(X):\n",
        "  y = []\n",
        "  for i in range(X.shape[0]):\n",
        "    point = X[i]\n",
        "    point_class = np.sign(point[0]**2 + point[1]**2 - 0.6)\n",
        "    y.append(point_class)\n",
        "  # pick random indices to flip with no replacement\n",
        "  indices = np.random.choice(X.shape[0], X.shape[0] // 10, replace=False)\n",
        "  for idx in indices:\n",
        "    y[idx] = -1 * y[idx]\n",
        "  return np.array(y)\n",
        "\n",
        "def predict(w, point):\n",
        "  return np.sign(np.dot(w, point))\n",
        "\n",
        "def noisy_linear_regression(N):\n",
        "  X = create_X(N)\n",
        "  #f =  np.sign(point[0]**2 + point[1]**2 - 0.6)\n",
        "  y = create_noisy_y(X)\n",
        "  w = find_weight_vec(X, y)\n",
        "  return w, X, y\n",
        "\n",
        "\n",
        "def noisy_in_sample_points_eval(N):\n",
        "  incorrect = 0\n",
        "  w, X, y = noisy_linear_regression(N)\n",
        "  for i in range(X.shape[0]):\n",
        "    point = X[i]\n",
        "    if predict(w, point) != y[i]:\n",
        "      incorrect += 1\n",
        "  return incorrect / N\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "yKfBSlE9Op7X"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The average fraction of incorrectly classified points, E_in for a noisy sample of f is: 0.5055090000000001 for N = 1000\n"
          ]
        }
      ],
      "source": [
        "# now simulate flipping some subset with noise to be incorrect\n",
        "sims = 1000\n",
        "total = 0\n",
        "for i in range(sims):\n",
        "  total += noisy_in_sample_points_eval(1000)\n",
        "print(\"The average fraction of incorrectly classified points, E_in for a noisy sample of f is: \" + str(total / sims) + \" for N = 1000\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "khHUHTcELoue"
      },
      "outputs": [],
      "source": [
        "def create_transformed_X(N):\n",
        "  X = [(0, 0, 0, 0, 0, 0) for i in range(N)]\n",
        "  for i in range(N):\n",
        "    x1 = random.uniform(min, max)\n",
        "    x2 = random.uniform(min, max)\n",
        "    X[i] = (1, x1, x2, x1 * x2, x1**2, x2**2)\n",
        "    #(changing the order of a point compared to earlier)\n",
        "  return np.array(X)\n",
        "\n",
        "def create_transformed_noisy_y(X):\n",
        "  y = []\n",
        "  for i in range(X.shape[0]):\n",
        "    point = X[i]\n",
        "    point_class = np.sign(point[1]**2 + point[2]**2 - 0.6)\n",
        "    y.append(point_class)\n",
        "  indices = np.random.choice(X.shape[0], X.shape[0] // 10, replace=False)\n",
        "  for idx in indices:\n",
        "    y[idx] = -1 * y[idx]\n",
        "  return np.array(y)\n",
        "\n",
        "def transformed_noisy_linear_regression(N):\n",
        "  X = create_transformed_X(N)\n",
        "  #f =  np.sign(point[0]**2 + point[1]**2 - 0.6)\n",
        "  y = create_transformed_noisy_y(X)\n",
        "  w = find_weight_vec(X, y)\n",
        "  return w, X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "JtgcxwhaQmYD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-0.9932198385686883, 0.0013060272363378596, -0.00043466277014730844, -0.0015980055310050659, 1.5584517271093243, 1.5623123732805801]\n"
          ]
        }
      ],
      "source": [
        "N = 1000\n",
        "sims = 1000\n",
        "w_avg = [0] * 6\n",
        "for i in range(sims):\n",
        "  w_new, _, _ = transformed_noisy_linear_regression(N)\n",
        "  for j in range(len(w_avg)):\n",
        "    w_avg[j] += w_new[j]\n",
        "for j in range(len(w_avg)):\n",
        "    w_avg[j] /= sims\n",
        "print(str(w_avg))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "nAiI26r2Mpwi"
      },
      "outputs": [],
      "source": [
        "# for number 10\n",
        "def out_of_sample_transformed_random_points_eval(N):\n",
        "  incorrect = 0\n",
        "  w, X, y = transformed_noisy_linear_regression(N)\n",
        "  num_points = 1000\n",
        "  new_points = create_transformed_X(num_points)\n",
        "  new_point_classification = create_transformed_noisy_y(new_points)\n",
        "  for i in range(new_points.shape[0]):\n",
        "    point = new_points[i]\n",
        "    if predict(w, point) != new_point_classification[i]:\n",
        "      incorrect += 1\n",
        "  return incorrect / num_points\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "KNmrLdZTWqzc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The average fraction of incorrectly classified points is: 0.12622599999999998 for out of sample with a nonlinear f\n"
          ]
        }
      ],
      "source": [
        "sims = 1000\n",
        "total = 0\n",
        "for i in range(sims):\n",
        "  total += out_of_sample_transformed_random_points_eval(1000)\n",
        "print(\"The average fraction of incorrectly classified points is: \" + str(total / sims) + \" for out of sample with a nonlinear f\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
